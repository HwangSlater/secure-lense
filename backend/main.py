from fastapi import FastAPI, Depends, HTTPException, UploadFile, File, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, Dict, List
import os
import uuid
import json
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path

from models import User, Analysis, CreditPurchase, get_db, init_db, pwd_context
from auth import create_access_token, get_current_user, ACCESS_TOKEN_EXPIRE_MINUTES
from analyzer import analyze_file, UPLOAD_DIR, ensure_upload_dir, schedule_file_deletion
import google.generativeai as genai

app = FastAPI(title="SecureLens API")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://frontend:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rate limiting storage
upload_counts = defaultdict(list)
MAX_UPLOADS_PER_HOUR = int(os.getenv("MAX_UPLOADS_PER_HOUR", "10"))

# Initialize Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Initialize database on startup
@app.on_event("startup")
def startup_event():
    init_db()
    ensure_upload_dir()


# Pydantic models
class LoginResponse(BaseModel):
    access_token: str
    token_type: str
    username: str
    role: str
    credits: int


class FileUploadResponse(BaseModel):
    scan_id: str
    filename: str
    risk_score: int
    risk_level: str
    clamav_result: Optional[str]
    yara_matches: List[str]
    shellcode_patterns: List[str]
    suspicious_strings: List[str]
    spearphishing_indicators: Optional[Dict]
    file_deleted_at: str


class AIAnalysisRequest(BaseModel):
    scan_id: str


class AIAnalysisResponse(BaseModel):
    analysis: str
    credits_used: int
    remaining_credits: int


class CreditChargeRequest(BaseModel):
    amount: int


class CreditChargeResponse(BaseModel):
    success: bool
    new_balance: int
    message: str


class CreditPurchaseHistoryItem(BaseModel):
    purchased_at: str
    amount: int
    balance_after: int


class AnalysisDetailResponse(BaseModel):
    scan_id: str
    filename: str
    risk_score: int
    risk_level: str
    clamav_result: Optional[str]
    yara_matches: List[str]
    shellcode_patterns: List[str]
    suspicious_strings: List[str]
    spearphishing_indicators: Optional[Dict]
    file_deleted_at: str
    uploaded_at: str


# Note: Analysis results and credit purchase history are now stored in database


# Rate limiting helper
def check_rate_limit(client_ip: str) -> bool:
    """Check if client has exceeded rate limit"""
    now = datetime.utcnow()
    cutoff = now - timedelta(hours=1)
    
    # Clean old entries
    upload_counts[client_ip] = [ts for ts in upload_counts[client_ip] if ts > cutoff]
    
    # Check limit
    if len(upload_counts[client_ip]) >= MAX_UPLOADS_PER_HOUR:
        return False
    
    # Add current upload
    upload_counts[client_ip].append(now)
    return True


# Authentication endpoints
@app.post("/auth/login", response_model=LoginResponse)
async def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    user = db.query(User).filter(User.username == form_data.username).first()
    if not user or not user.verify_password(form_data.password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
    
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.username}, expires_delta=access_token_expires
    )
    
    return LoginResponse(
        access_token=access_token,
        token_type="bearer",
        username=user.username,
        role=user.role,
        credits=user.credits
    )


@app.get("/auth/me")
async def get_current_user_info(current_user: User = Depends(get_current_user)):
    return {
        "username": current_user.username,
        "role": current_user.role,
        "credits": current_user.credits
    }


# File upload and analysis endpoint
@app.post("/files/upload", response_model=FileUploadResponse)
async def upload_file(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user),
    request: Request = None,
    db: Session = Depends(get_db)
):
    # Rate limiting
    client_ip = request.client.host if request else "unknown"
    if not check_rate_limit(client_ip):
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail="ì‹œê°„ë‹¹ ì—…ë¡œë“œ ì œí•œ(10ê°œ)ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. 1ì‹œê°„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            headers={"Retry-After": "3600"}
        )
    
    # Generate unique filename
    file_id = str(uuid.uuid4())
    file_ext = Path(file.filename).suffix
    stored_filename = f"{file_id}{file_ext}"
    file_path = os.path.join(UPLOAD_DIR, stored_filename)
    
    try:
        # Save uploaded file
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # Analyze file
        analysis_result = analyze_file(file_path, file.filename)
        
        # Prepare response
        scan_id = file_id
        
        # Format response
        response_data = {
            "scan_id": scan_id,
            "filename": file.filename,
            "risk_score": analysis_result["risk_score"],
            "risk_level": analysis_result["risk_level"],
            "clamav_result": analysis_result.get("clamav_result"),
            "yara_matches": analysis_result.get("yara_matches", []),
            "shellcode_patterns": analysis_result.get("binary_analysis", {}).get("shellcode_patterns", []),
            "suspicious_strings": analysis_result.get("binary_analysis", {}).get("suspicious_strings", []),
            "spearphishing_indicators": None,
            "file_deleted_at": (datetime.utcnow() + timedelta(hours=1)).isoformat() + "Z"
        }
        
        # Add email-specific indicators
        if analysis_result.get("email_analysis"):
            email_analysis = analysis_result["email_analysis"]
            response_data["spearphishing_indicators"] = {
                "spoofed_sender": email_analysis.get("spoofed_sender", False),
                "phishing_keywords": email_analysis.get("phishing_keywords", []),
                "suspicious_urls": email_analysis.get("suspicious_urls", []),
                "has_double_extension": email_analysis.get("has_double_extension", False),
                "header_analysis": email_analysis.get("header_analysis", {})
            }
        
        # Store analysis result in database
        db_analysis = Analysis(
            scan_id=scan_id,
            user_id=current_user.id,
            filename=file.filename,
            analysis_data=analysis_result,
            risk_score=analysis_result["risk_score"],
            risk_level=analysis_result["risk_level"],
            uploaded_at=datetime.utcnow()
        )
        db.add(db_analysis)
        db.commit()
        db.refresh(db_analysis)
        
        # Schedule file deletion
        schedule_file_deletion(file_path, delay_hours=1)
        
        return FileUploadResponse(**response_data)
        
    except ValueError as e:
        # Validation error
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        # Other errors
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# AI analysis endpoint
@app.post("/analysis/ai", response_model=AIAnalysisResponse)
async def ai_analysis(
    request: AIAnalysisRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    scan_id = request.scan_id
    
    # Check if analysis result exists in database
    db_analysis = db.query(Analysis).filter(Analysis.scan_id == scan_id).first()
    if not db_analysis:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # Check if user owns this analysis
    if db_analysis.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ì´ ë¶„ì„ ê²°ê³¼ì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # Check if AI analysis already exists
    if db_analysis.ai_analysis:
        return AIAnalysisResponse(
            analysis=db_analysis.ai_analysis,
            credits_used=0,
            remaining_credits=current_user.credits
        )
    
    analysis_data = db_analysis.analysis_data
    filename = db_analysis.filename
    
    # Check credits (unless admin)
    credits_used = 0
    if current_user.role != "ADMIN":
        if current_user.credits <= 0:
            raise HTTPException(
                status_code=status.HTTP_402_PAYMENT_REQUIRED,
                detail="AI ë¶„ì„ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¶„ì„ í‹°ì¼“ì´ í•„ìš”í•©ë‹ˆë‹¤. ì¶©ì „í•˜ê¸°ì—ì„œ í‹°ì¼“ì„ êµ¬ë§¤í•´ì£¼ì„¸ìš”."
            )
        
        # Deduct credit
        current_user.credits -= 1
        db.commit()
        credits_used = 1
    
    # Prepare Gemini prompt (Korean)
    prompt = f"""
ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì‚¬ì´ë²„ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¼ë°˜ì¸ë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê²°ê³¼:**

- íŒŒì¼ëª…: {filename}
- ìœ„í—˜ë„ ì ìˆ˜: {analysis_data['risk_score']}/100
- ìœ„í—˜ë„ ë“±ê¸‰: {analysis_data['risk_level']}
- ClamAV íƒì§€: {analysis_data.get('clamav_result', 'ì—†ìŒ')}
- YARA íƒì§€ ê·œì¹™: {', '.join(analysis_data.get('yara_matches', [])) if analysis_data.get('yara_matches') else 'ì—†ìŒ'}
- ì‰˜ì½”ë“œ íŒ¨í„´: {', '.join(analysis_data.get('binary_analysis', {}).get('shellcode_patterns', [])) if analysis_data.get('binary_analysis', {}).get('shellcode_patterns') else 'ì—†ìŒ'}
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë¬¸ìì—´: {', '.join(analysis_data.get('binary_analysis', {}).get('suspicious_strings', [])[:10]) if analysis_data.get('binary_analysis', {}).get('suspicious_strings') else 'ì—†ìŒ'}
- ìŠ¤í”¼ì–´í”¼ì‹± ì§€í‘œ: {json.dumps(analysis_data.get('email_analysis', {}), ensure_ascii=False, indent=2) if analysis_data.get('email_analysis') else 'ì—†ìŒ'}

**ì‘ì—…:**

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

## ğŸ¯ ìœ„í—˜ë„ í‰ê°€

[{analysis_data['risk_level']}] - 5ë‹¨ê³„ ì¤‘ ì„ íƒ

## ğŸ“‹ 3ì¤„ ìš”ì•½

1. ì´ íŒŒì¼ì˜ ì •ì²´ê°€ ë¬´ì—‡ì¸ì§€
2. ì–´ë–¤ ìœ„í—˜ì´ ìˆëŠ”ì§€
3. ì™œ ìœ„í—˜í•œì§€

## ğŸ£ ìŠ¤í”¼ì–´í”¼ì‹± ê°€ëŠ¥ì„±

[0-100%] - ì´ íŒŒì¼ì´ ìŠ¤í”¼ì–´í”¼ì‹± ê³µê²©ì˜ ì¼ë¶€ì¼ í™•ë¥ 

## âš ï¸ ë°œê²¬ëœ ìœ„í˜‘ ìš”ì†Œ

- (êµ¬ì²´ì ì¸ ì¦ê±° ë‚˜ì—´)

## âœ… ëŒ€ì‘ ë°©ë²•

1. ì¦‰ì‹œ í•´ì•¼ í•  ì¡°ì¹˜
2. ì˜ˆë°©ì„ ìœ„í•œ ì¡°ì¹˜

## ğŸ“š ìœ ì‚¬ ê³µê²© ì‚¬ë¡€

ì‹¤ì œ ë°œìƒí–ˆë˜ ìœ ì‚¬í•œ ê³µê²© 1ê°œë¥¼ ê°„ë‹¨íˆ ì†Œê°œ (ì˜ˆ: "2024ë…„ êµ­ì„¸ì²­ ì‚¬ì¹­ ì´ë©”ì¼ ê³µê²©")

**ì£¼ì˜ì‚¬í•­:**

- ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ì‹œ ê´„í˜¸ë¡œ ì‰¬ìš´ ì„¤ëª… ì¶”ê°€ (ì˜ˆ: "ì‰˜ì½”ë“œ(ì•…ì„± ëª…ë ¹ì–´)")
- ìœ„í—˜ë„ë¥¼ ê³¼ì¥í•˜ê±°ë‚˜ ì¶•ì†Œí•˜ì§€ ë§ ê²ƒ
- êµ¬ì²´ì ì¸ ì¦ê±° ê¸°ë°˜ìœ¼ë¡œë§Œ ì„¤ëª…
- ëª¨ë“  ì„¤ëª…ì€ í•œêµ­ì–´ë¡œ ì‘ì„±
"""
    
    try:
        # Call Gemini API
        if not GEMINI_API_KEY:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="AI ë¶„ì„ ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=2000,
            )
        )
        
        analysis_text = response.text
        
        # Save AI analysis to database
        db_analysis.ai_analysis = analysis_text
        db.commit()
        
    except Exception as e:
        # Handle API errors gracefully
        error_msg = str(e).lower()
        if "429" in error_msg or "rate limit" in error_msg:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="AI ë¶„ì„ ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ í˜¼ì¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            # Return generic safety message
            analysis_text = f"""## ğŸ¯ ìœ„í—˜ë„ í‰ê°€

{analysis_data['risk_level']}

## ğŸ“‹ 3ì¤„ ìš”ì•½

1. ì´ íŒŒì¼ì€ ì—¬ëŸ¬ ë³´ì•ˆ ì—”ì§„ì—ì„œ ìœ„í—˜ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤
2. ì‹¤í–‰ ì‹œ ì‹œìŠ¤í…œì— ì•…ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
3. ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ê³¼ í–‰ìœ„ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤

## âš ï¸ ë°œê²¬ëœ ìœ„í˜‘ ìš”ì†Œ

- ë³´ì•ˆ ì—”ì§„ íƒì§€: {analysis_data.get('clamav_result', 'ì—†ìŒ')}
- YARA ê·œì¹™ ë§¤ì¹­: {len(analysis_data.get('yara_matches', []))}ê°œ
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ë°œê²¬

## âœ… ëŒ€ì‘ ë°©ë²•

1. ì´ íŒŒì¼ì„ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”
2. ì‹œìŠ¤í…œì„ ì™„ì „íˆ ê²€ì‚¬í•˜ê³  í•„ìš”ì‹œ ê²©ë¦¬í•˜ì„¸ìš”
3. í–¥í›„ ìœ ì‚¬í•œ íŒŒì¼ì„ ë°›ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”

## ğŸ“š ìœ ì‚¬ ê³µê²© ì‚¬ë¡€

ì•…ì„± ì½”ë“œê°€ ì´ë©”ì¼ ì²¨ë¶€íŒŒì¼ë¡œ ìœ í¬ë˜ëŠ” ì‚¬ë¡€ëŠ” ì§€ì†ì ìœ¼ë¡œ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.
"""
    
    # Get updated credits
    db.refresh(current_user)
    
    return AIAnalysisResponse(
        analysis=analysis_text,
        credits_used=credits_used,
        remaining_credits=current_user.credits
    )


# Credit charging endpoint
@app.post("/credits/charge", response_model=CreditChargeResponse)
async def charge_credits(
    request: CreditChargeRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if request.amount <= 0:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ì¶©ì „í•  í‹°ì¼“ ìˆ˜ëŠ” 1ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤."
        )
    
    current_user.credits += request.amount
    db.commit()
    db.refresh(current_user)

    # Record purchase history in database
    purchase = CreditPurchase(
        user_id=current_user.id,
        amount=request.amount,
        balance_after=current_user.credits,
        purchased_at=datetime.utcnow()
    )
    db.add(purchase)
    db.commit()
    
    return CreditChargeResponse(
        success=True,
        new_balance=current_user.credits,
        message=f"{request.amount}ê°œì˜ ë¶„ì„ í‹°ì¼“ì´ ì¶©ì „ë˜ì—ˆìŠµë‹ˆë‹¤."
    )


# Analysis history endpoint
@app.get("/analysis/history")
async def get_analysis_history(
    current_user: User = Depends(get_current_user),
    limit: int = 10,
    db: Session = Depends(get_db)
):
    # Get recent analyses from database
    analyses = db.query(Analysis).filter(
        Analysis.user_id == current_user.id
    ).order_by(Analysis.uploaded_at.desc()).limit(limit).all()
    
    user_analyses = []
    for analysis in analyses:
        user_analyses.append({
            "scan_id": analysis.scan_id,
            "filename": analysis.filename,
            "risk_score": analysis.risk_score,
            "risk_level": analysis.risk_level,
            "uploaded_at": analysis.uploaded_at.isoformat() + "Z"
        })
    
    return {"analyses": user_analyses}


@app.get("/analysis/{scan_id}", response_model=AnalysisDetailResponse)
async def get_analysis_detail(
    scan_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Get detailed analysis result for a specific scan_id from database.
    """
    db_analysis = db.query(Analysis).filter(Analysis.scan_id == scan_id).first()
    if not db_analysis:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # Check if user owns this analysis
    if db_analysis.user_id != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ì´ ë¶„ì„ ê²°ê³¼ì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."
        )

    analysis = db_analysis.analysis_data

    # Reuse the same structure as file upload response
    clamav_result = analysis.get("clamav_result")
    yara_matches = analysis.get("yara_matches", [])
    binary_analysis = analysis.get("binary_analysis", {})
    shellcode_patterns = binary_analysis.get("shellcode_patterns", [])
    suspicious_strings = binary_analysis.get("suspicious_strings", [])

    spearphishing_indicators = None
    if analysis.get("email_analysis"):
        email_analysis = analysis["email_analysis"]
        spearphishing_indicators = {
            "spoofed_sender": email_analysis.get("spoofed_sender", False),
            "phishing_keywords": email_analysis.get("phishing_keywords", []),
            "suspicious_urls": email_analysis.get("suspicious_urls", []),
            "has_double_extension": email_analysis.get("has_double_extension", False),
            "header_analysis": email_analysis.get("header_analysis", {}),
        }

    # File deletion time is approximated as upload time + 1 hour
    uploaded_at = db_analysis.uploaded_at
    file_deleted_at = (uploaded_at + timedelta(hours=1)).isoformat() + "Z"

    return AnalysisDetailResponse(
        scan_id=scan_id,
        filename=db_analysis.filename,
        risk_score=analysis["risk_score"],
        risk_level=analysis["risk_level"],
        clamav_result=clamav_result,
        yara_matches=yara_matches,
        shellcode_patterns=shellcode_patterns,
        suspicious_strings=suspicious_strings,
        spearphishing_indicators=spearphishing_indicators,
        file_deleted_at=file_deleted_at,
        uploaded_at=uploaded_at.isoformat() + "Z",
    )


@app.get("/credits/history", response_model=List[CreditPurchaseHistoryItem])
async def get_credit_history(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    Get credit purchase history for the current user from database.
    """
    purchases = db.query(CreditPurchase).filter(
        CreditPurchase.user_id == current_user.id
    ).order_by(CreditPurchase.purchased_at.asc()).all()
    
    # Return in chronological order (oldest first)
    return [
        CreditPurchaseHistoryItem(
            purchased_at=purchase.purchased_at.isoformat() + "Z",
            amount=purchase.amount,
            balance_after=purchase.balance_after,
        )
        for purchase in purchases
    ]


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

